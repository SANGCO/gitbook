

## Chapter 1. 인프라 아키텍처를 살펴보자



### 1-1. 시작하며



### 1-2. 집약형과 분할형 아키텍처



#### 집약형 아키텍처

- `그림 1.3` 대형 컴퓨터에 대한 고민 참고
  - 컴퓨터를 구성하는 주요 부품은 모두 다중화돼 있어서 하나가 고장 나더라도 업무를 계속할 수 있다.
  - 복수의 서로 다른 업무 처리를 동시에 처리할 수 있도록 유한 리소스 관리를 하고 있다.
    - 이를 통해 하나의 처리가 실수로 대량의 요청을 보내더라도 다른 처리에 영향을 주지 않도록 되어 있다.  
- 현재는 가격이 싸고 확장성이 높은 분할형이 주로 사용되고 있다.
- 장단점
  - 장점
    - 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단하다.
    - 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능이다.
  - 단점
    - 대형 컴퓨터의 도입 비용과 유지 비용이 크다.
    - 확장성에 한계가 있다.



#### 분할형 아키텍처

- `그림 1.4` 분할형 아키텍처 참고
  - 분할형 아키텍처는 여러 대의 컴퓨터를 조합해서 하나의 시스템을 구축하는 구조다.
- 분할형 아키텍처는 표준 OS나 개발 언어를 이용하기 때문에 '오픈 시스템'이라고 부른다.
- 여러 대의 컴퓨터를 연결해서 이용하기 때문에 '분산 시스템'이라 부르는 경우도 있다.
- 장단점
  - 장점
    - 낮은 비용으로 시스템을 구축할 수 있다.
    - 서버 대수를 늘릴 수 있어서 확장성이 높다.
  - 단점
    - 대수가 늘어나면 관리 구조가 복잡해진다.
    - 한 대가 망가지면 영향 범위를 최소화하기 위한 구조를 검토해야 한다.



#### 물리 서버와 논리 서버의 차이

- 분할형 아키텍처에서 이용되는 컴퓨터를 '서버'라고 한다.
  - 서버라는 용어는 컴퓨터 자체(하드웨어)를 가리키는 경우도 있고, 컴퓨터에서 동작하고 있는 소프트웨어를 가리키는 경우도 있다.
- 서버라는 용어는 원래 '특정 역할에 특화된 것'을 의미한다.
  - 레스토랑의 웨이터를 서버라고 부르는 경우도 있다.
    - 주문 접수나 음식을 내오는 것에 특화돼 있는 웨이터
- `그림 1.5` 서버라는 용어가 지니는 다양한 의미
  - 물리적인 서버
    - 물리 서버
  - 논리적인 서버
    - 웹 서버
    - DB 서버



### 1-3. 수직 분할형 아키텍처

- 분할형에서는 서버 분할 방식, 즉 역할 분담을 고려해야 한다. 
  - 각각의 서버가 전혀 다른 작업을 하는 것인지, 아니면 비슷한 작업을 하는 것인지에 대한 관점이다.



#### 클라이언트-서버형 아키텍처

- `그림 1.6` 클라이언트와 서버의 역할 분담 참고
  - 클라이언트-서버형의 특징은 클라이언트 측에 전용 소프트웨어를 설치해야 한다는 것이다.
- 장단점
  - 장점
    - 클라이언트 측에서 많은 처리를 실행할 수 있어서 소수의 서버로 다수의 클라이언트를 처리할 수 있다.
  - 단점
    - 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다.
    - 서버 확장성에 한계가 발생할 수 있다.



#### 3계층형 아키텍처

- `그림 1.7` 3계층 서버의 역할 분담 참고
- 3계층형
  - 프레젠테이션 계층
    - 사용자 입력을 받는다.
    - 웹 브라우저 화면을 표시한다.
  - 애플리케이션 계층
    - 사용자 요청(request)에 따라 업무 처리를 한다.
  - 데이터 계층
    - 애플리케이션 계층의 요청에 따라 데이터 입출력을 한다.
- 클라이언트-서버형에 비해 특정 서버에 부하가 집중되는 문제가 해결된다는 것이 장점이다.
  - 또한, 업무 애플리케이션 갱신에 따른 클라이언트 업데이트가 필요 없으며, 사용자는 웹 브라우저만 준비하면 된다.
- 장단점
  - 장점
    - 서버 부하 집중 개선
    - 클라이언트 단말의 정기 업데이트가 불필요
    - '처리 반환'에 의한 서버 부하 저감
  - 단점
    - 구조가 클라이언트-서버 구성보다 복잡하다.



#### 웹은 클라이언트-서버형을 대체할 수 있을까?

- 기존 웹에서는 브라우저가 웹 서버에 요청을 보내서 그것을 받아 처리하는 구조였지만, 웹 소켓(web socket) 방식에서는 요청이 없어도 웹 서버가 브라우저에 데이터를 전달(푸시)할 수 있다.
- 브라우저는 단순히 '인터넷 콘텐츠 표시용 스프트웨어'가 아닌, '다기능(리치(Rich)) 단말'이 되고 있다.
  - 이것은 3계층 아키텍처 상에서 클라이언트-서버형 시스템을 동작시키고 있는것과 같다.
- 집약형에서 분할형으로 패러다임이 이동했지만, 최근 하드웨어 제조사는 역으로 '하드웨어와 소프트웨어 일체형' 제품을 판매하고 있다.
- 반복되고 있는 것처럼 보여도 더 나은 아키텍처를 향한 진화는 계속되고 있다.



### 1-4. 수평 분할형 아키텍처

- '수평 분할형 아키텍처'는 용도가 같은 서버를 늘려나가는 방식이다.
  - 서버 대수가 늘어나면 한 대가 시스템에 주는 영향력이 낮아져서 안정성이 향상된다.
  - 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있다.
- 수직 분할형과 수평 분할형은 배타적인 관계가 아니다.
  - 대부분의 시스템이 이 두 가지 방식을 함께 채택하고 있다.



#### 단순 수평 분할형 아키텍처

- `그림 1.8` 같은 기능을 가진 복수의 시스템으로 단순 분할한다 참고
  - 그림을 보면 수평 분할에서는 서울 본사와 부산 지사 시스템이 완전히 분할돼있다.
    - 서울에서 부산 지사 정보를 알고 싶으면 부산 지사 측 시스템에 접속하면 된다.
  - 수평 분할을 'sharding(샤딩)'이나 'partitioning(파티셔닝)'이라 부르기도 한다.
  - 이 구성에서는 시스템이 둘로 분할됨으로써 시스템 전체 처리 성능을 두 배로 향상시킬 수 있다.
    - 두 개의 독립된 시스템이 생성되기에 서울 측 시스템에 장애가 발생하더라도 부산 측 시스템에는 전혀 영향을 주지 않아 독립성이 향상된다.

- 장단점
  - 장점
    - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
    - 분할한 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다.
  - 단점
    - 데이터를 일원화해서 볼 수 없다.
    - 애플리케이션 업데이트는 양쪽을 동시에 해 주어야 한다.
    - 처리량이 균등하게 분할돼 있지 않으면 서버별 처리량에 치우침이 생긴다.



#### 공유형 아키텍처

- `그림 1.9` 데이터 계층을 상호 접속한다 참고
  - 그림은 데이터 계층의 상호 접속 예다.
  - 오라클 제품인 Oracle Database의 클러스터 기능(Real Application Clusters, RAC)에서는 어떤 DB 서버에 접속해도 같은 결과를 얻을 수 있도록 내부적으로 데이터 교환을 하고 있다.

- 장단점
  - 장점
    - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
    - 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다.
  - 단점
    - 분할한 시스템 간 독립성이 낮아진다.
    - 공유한 계층의 확장성이 낮아진다.



#### 가상화 진행 상황

- 집약과 분할형 양쪽의 장점을 취하는 접근법이 '가상화'다.
  - 물리 서버를 가상화 기능으로 여러 대의 가상 서버로 분할하는 방식이다.
  - 그림 A에 있는 예처럼, 두 대의 웹 서버와 두 대의 AP 서버, 총 네 대의 가상화 서버를 하나의 물리 서버에 운영하고 있다.
    - 또한, 물리 서버를 이중화해서 한 대가 망가지더라도 계속해서 운영할 수 있다.



### 1-5. 지리 분할형 아키텍처

- 수직, 수평 분할 아키텍처를 조합함으로써 목적에 적합한 구성을 만들 수 있다.

- 지리적으로 분할하는 아키텍처
  - 업무 연속성 및 시스템 가용성을 높이기 위한 방식



#### 스탠바이형 아키텍처

- `그림 1.10` 액티브-스탠바이(active-standby) 구성 참고



#### 재해 대책형 아키텍처

- `그림 1.11` 평상시의 재해 대책 사이트 데이터 방영, `그림 1.12` 재해 발생 시의 이용 참고



#### 클라우드형 아키텍처

- `그림 1.13` 시스템 전체를 클라우드에 배치하는 경우



#### 기술은 대물림되고 있다







## Chapter 2. 서버를 열어 보자



### 2-1. 물리 서버



#### 서버 외관과 설치 장소



#### 서버 내부 구성



### 2-2. CPU



### 2-3. 메모리

- `그림 2.10` 캐시를 여러 단으로 배치해서 대기 시간을 줄인다 참고
  - 캐시를 여러 단계로 배치
  - 각 코어별로 자신의 L1, L2 캐시를 가지고 있다.
  - 초고속으로 액세스하고 싶은 데이터는 L1 캐시에
  - 준고속으로 액세스하고 싶은 데이터는 L2 캐시에
  - 이 아키텍처에서는 L1, L2 캐시에 있는 데이터가 L3에도 존재하기 때문에 다른 코어는 자신 이외의 캐시를 확인하지 않고 L3 캐시만 확인하면 되는 구조다.
- `그림 2.11` 미리 읽어서 메모리 처리 지연을 경감
  - 메모리에는 미리 데이터를 CPU에 전달해서 처리 지연을 줄이는 '메모리 인터리빙(memory interleaving)'이라는 기능이 있다.
  - `그림 2.10`의 왼쪽 아래에 메모리 컨트롤러와 채널(channel)이 있다.
    - 이것을 자세히 표현한 것이 `그림 2.11`이다.
    - 채널은 메모리와 CPU 간 데이터 경로를 말한다.
  - 최대 세 개의 채널을 사용해서 데이터1을 요구하면 데이터 2와 3도 함께 보내 버린다.
    - 이것은 대부분의 데이터가 연속해서  액세스된다는 규칙을 기반으로 만들어진 것이다.
    - 먼저 읽어서 처리 지연을 줄여주는 것이다.



### 2-4. I/O 장치



#### 하드 디스크 드라이브(HDD)

- SSD(Solid State Disk, 반도체 디스크)
  - 물리적인 회전 요소를 사용하지 않는 디스크
  - SSD는 메모리와 같이 반도체로 만들어졌지만, 전기가 없어도 데이터가 사라지지 않는다.
  - SSD의 등장으로 인해 메모리와 기억 장치 간 속도 차이가 거의 없어지고 있다.
- HDD가 많이 탑재돼 있는 하드웨어를 '스토리지(Storage, 저장소)'라고 한다.
- 서버와 I/O 시에는 HDD가 직접 데이터 교환을 하는 것이 아니라 캐시를 통해서 한다.
  - '캐시'라는 개념에 대해서는 5장에서 자세히 다루기 때문에 여기서는 메모리처럼 고속으로 I/O가 가능한 하드웨어라는 정도로 알면 된다.
- 보통은 서버 시스템 포트에 FC 포트가 없기 때문에 PCI 슬롯에 HBA라는 카드를 삽입한다.
  - FC 포트
    - SAN(Storage Area Network)에 접속하기 위한 파일 채널 인터페이스
      - 대형 저장소와 연결할 때는 SAN이라는 네트워크를 경유한다.
        - 일반적으로 연결시에 파이버 채널(Fibre Channel, FC)이라는 케이블을 사용한다. 

- `그림 2.13` 저장소 캐시에 I/O하는 과정 참고
  - 라이트 백(write back)
    - 읽기/쓰기 시에 캐시라는 메모리 영역에 액세스한다.
    - 읽기 캐시의 경우는 캐시 상에 데이터 복사본만 있으면 된다.
    - 쓰기 캐시의 경우는 캐시에만 데이터를 기록하고 완료했다고 간주하기 때문에 데이터를 잃을 가능성이 있다.
      - 장점으로는 캐시에 저장해서 쓰기 처리가 종료되기 때문에 고속 I/O를 실현할 수 있다는 점이다.
      - 대부분의 저장소 제품에서는 이 캐시를 별도의 캐시와 미러링해서 안정성을 높이고 있다.
  - 라이트 스루(write through)
    - 읽기/쓰기 시에 캐시와 HDD 모두에 액세스한다. 
    - 읽기 시에 캐시에 데이터가 없으면 읽기 처리를 위해 디스크에 액세스한다.
    - 쓰기 시에는 캐시와 디스크를 모두 읽어서 라이트 백과 비교하고, 더 확실한 쪽에 쓰기 처리를 위해 액세스한다.
      - 이 경우 쓰기 캐시의 장점은 없다. 
  - 기본적으로는 캐시의 장점을 살리기 위해 '라이트 백'으로 설정한다.



#### 네트워크 인터페이스

- `그림 2.6` '컴포넌트들은 버스(bus)로 연결된다'를 다시 보자.
  - HDD와 네트워크 인터페이스는 I/O 핸들러라는 컨트롤러에 연결돼 있다.
  - CPU 관점에서는 HDD도 네트워크도 외부 I/O라는 의미에서는 동일하다.



#### I/O 제어

- IA(Intel Architecture) 서버 아키텍처에서 I/O 제어는 'I/O 핸들러(IOH)' 또는 'I/O 컨트롤러(ICH)'라는 제어장치를 통해 한다.
  - IOH는 CPU와 가까운 곳에 있어서 '노스 브릿지(north bridge)'라고 한다.
  - ICH는 '사우스 브릿지(south bridge)'라고 한다.
- `그림 2.15` IOH와 ICH를 중심적으로 보자 참고
  - PCI 버스는 컴퓨터 메인보드에 주변 장치를 장착하는 데 쓰이는 컴퓨터 버스의 일종이다.
  - PCI의 x8, x16이라는 숫자는 I/O 회선이 몇 개 연결되는지를 의미한다.
    - x8이라면 8선이라는 의미
    - IOH에는 PCI 회선이 처리할 수 있는 선 수가 제한돼 있다.
      - Sun Fire X4170에 탑재돼 있는 IOH에서는 최대 36선으로 이것을 모두 사용하고 있다.
  - IOH
    - IOH는 고속 처리가 필요한 I/O(PCI Express나 네트워크 등)를 제어한다.
      - 이전에는 메모리 I/O 제어가 주요 역할이었지만, CPU에 그 역할이 옮겨갔다.
    - IOH는 CPU 간 데이터 전송 제어도 한다.
      - 현재 CPU와 IOH 간에는 퀵 패스 인터커넥트(Quick Path Interconnect)라는 고속 버스로 연결돼 있다.
  - ICH
    - ICH는 속도가 느려도 괜찮은 DVD나 USB 등의 I/O 제어를 담당하며, IOH 간 데이터 전송 제어도 한다.
- `그림 2.16` 다양한 I/O 예 참고
  - CPU 외에도 다양한 컨트롤러나 칩이 존재하는 이유는 CPU가 해야 할 연산에 더 집중하기 위한 것이라 할 수 있다.
    - CPU와 칩셋의 관계는 역할 분담을 위한 것이다.
  - I/O와 가까운 곳(즉, CPU에서 멀리 있는 곳)에서 처리하는 것이 더 효율적이다.
  - 그림을 보면 HDD의 I/O와 DVD의 I/O 경로가 물리적으로 다르다는 것을 알 수 있다.



### 2-5. 버스



#### 대역



#### 버스 대역



### 2-6. 정리





## Chapter 3. 3계층형 시스템을 살펴보자



### 3-1. 3계층형 시스템의 구성도



### 3-2. 주요 개념 설명



Column 막대 인간의 모험
Column 커널은 결코 견고하지 않다



### 3-3. 웹 데이터 흐름

Column 데이터와 함께 전달되는 당신을 향한 마음
Column RDBMS와 KVS의 소리 없는 전쟁
Column 높은 하늘을 날다 ― 조감도











Chapter 4 인프라를 지탱하는 기본 이론 79
4.1 | 웹 데이터 흐름 80
Column 병렬과 병행 86
4.2 | 동기/비동기 86
Column C10K 문제 93
4.3 | 큐 94
4.4 | 배타적 제어 101
Column 멀티 프로세서 시스템에서는 배타적 제어가 어렵다 106
4.5 | 상태 저장/상태 비저장 107
4.6 | 가변 길이/고정 길이 113
4.7 | 데이터 구조(배열과 연결 리스트) 119
4.8 | 탐색 알고리즘(해시/트리 등) 124

Chapter 5 인프라를 지탱하는 응용 이론 133
5.1 | 캐시 134
5.2 | 끼어들기 139
5.3 | 폴링 144
5.4 | 핑퐁 149
5.5 | 저널링 156
Column 변화는 항상 순식간에 일어난다 162
5.6 | 복제 163
5.7 | 마스터-슬레이브 168
5.8 | 압축 172
5.9 | 오류 체크/오류 수정 178

Chapter 6 시스템을 연결하는 네트워크 구조 185
6.1 | 네트워크 186
6.2 | 【기초】 계층 구조란? 187
6.3 | 【기초】 프로토콜이란? 191
Column 표준화 단체에 대해서 194
6.4 | TCP/IP를 이용하고 있는 현재의 네트워크 196
6.5 | 【레이어 7】 애플리케이션 계층의 프로토콜 HTTP 199
Column 한 번 잡으면 놓아주지 않는다 204
6.6 | 【레이어 4】 전송 계층 프로토콜 TCP 205
Column 인터넷의 주인은 누구? 207
6.7 | 【레이어 3】 네트워크 계층의 프로토콜 IP 216
Column IP 주소 고갈과 IPv6 221
Column IP 헤더에서 체크섬이 사라진 날 224
6.8 | 【레이어 2】 데이터 링크 계층의 프로토콜 이더넷 224
6.9 | TCP/IP를 이용한 통신 이후 231
Column NIC의 끼어들기와 패킷 처리 235

Chapter 7 무정지를 위한 인프라 구조 237
7.1 | 안정성 및 이중화 238
Column 장애 보호 240
7.2 | 서버 내 이중화 241
7.3 | 저장소 이중화 248
7.4 | 웹 서버 이중화 256
Column 장애 괴담 첫 번째 이야기, ‘벌써 시간이 다 됐어?’ 256
Column DSR(Direct Server Return) 264
7.5 | AP 서버 이중화 265
7.6 | DB 서버 이중화 270
Column 장애 괴담 두 번째 이야기, ‘진단 때문에 죽었다’ 279
7.7 | 네트워크 장비 이중화 279
Column 장애 괴담 세 번째 이야기, ‘브로드캐스트 스톰’ 289
7.8 | 사이트 이중화 290
7.9 | 감시 293
7.10 | 백업 301
7.11 | 정리 305

Chapter 8 성능 향상을 위한 인프라 구조 307
8.1 | 응답과 처리량 308
Column 가장 중요한 응답 시간은? 311
8.2 | 병목 현상이란? 315
Column CAP 정리를 익혀서 초능력자가 되자 317
Column 병목 현상의 숙명의 적, 데이터베이스 321
8.3 | 3계층형 시스템 그림을 통해 본 병목 현상 321
Column 여유가 있는 노련한 시스템 324
Column C는 자바보다 빠르다? 333
Column 아이들을 공원에서 놀게 하자 341
Column ORDER(N) ? 일인분 나왔습니다 344
Column 대역이 가장 중요한 것일까? 347
8.4 | 정리 354